\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{multirow}
\usepackage{parskip}

\begin{document}
\title{Predicting the Outcome of Soccer Matches}
\author{Ayaan Kazerouni and Harsh Patel}
\date{}
\maketitle

\section{Problem Statement}
Soccer is a widely played sport, and is arguably the only globally played sport.
We thought it would be interesting to develop a model that could predict the winner of a soccer game, a task called the `holy grail' by the provider of the dataset. Our problem statement is formally defined as follows:

We have access to a dataset that has featrures from matches already played, ranging from the number of goals scored by home team and away team to different attributes of the players of individual teams. Given this dataset, our goal is to build a model that predicts the winner of the match fairly accurately.
As with a lot of parameters in data analytics and machine learning, `fairly accurately' is a vague term, but we define it as anything better than 53\%, which is the accuracy achieved by the dataset provider (and the target accuracy we mentioned in our proposal).
We are unaware of the features used in their model or the nature of their model.
We have also not looked at what others have done with this publicly available dataset.
The work presented in this report is solely our own.

\section{Data Description}
\label{sec:data-desc}
We have chosen a European soccer dataset~\cite{mathien1}, the nature of which as described by the provider is:
\begin{itemize}
  \setlength\itemsep{0em}
  \item{+25,000 matches}
  \item{+10,000 playres}
  \item{11 European countries with their lead championship}
  \item{Seasons 2008 to 2016}
  \item{Players and Teams' attributes sourced from EA Sports' FIFA video game series, including the weekly updates}
  \item{Team line up with squad formation (X, Y coordinates)}
  \item{Betting odds from up to 10 providers}
  \item{Detailed match events (goal types, possession, corner, cross, fouls, cards etc...) for +10,000 matches}
\end{itemize}
We are thankful to the data provider for consolidating and organizing the data from various online sources.
This has reduced work on finding relevant data on our part considerably.

The data is provided in a relational database (SQLite3) of \textit{Matches}, \textit{Players}, \textit{Player-Attributes}, \textit{Teams}, \textit{Team-Attributes}, \textit{Leagues}, and \textit{Countries}.
A description of the magnitude of the data is provided in Table~\ref{tab:data-desc}.

\begin{table}[ht]
\centering
\begin{tabular}{|l|r|r|}
\hline
\textbf{}                   & \textbf{Count} & \textbf{Dimensions} \\ \hline
\textbf{Match}              & 25979          & 115                 \\ \hline
\textbf{Teams}              & 299            & 5                   \\ \hline
\textbf{Team\_Attributes}   & 1458           & 25                  \\ \hline
\textbf{Player}             & 11060          & 7                   \\ \hline
\textbf{Player\_Attributes} & 183978         & 42                  \\ \hline
\textbf{Country}            & 11             & 2                   \\ \hline
\textbf{League}             & 11             & 3                   \\ \hline
\end{tabular}
\caption{Magnitude of the available data}
\label{tab:data-desc}
\end{table}

Here, the active reader would have noticed that there are only 299 teams but 1458 Team\_Attribute rows.
This is because the data provider has provided the attributes for some teams over a span of several years and intuitively enough, the attributes keep changing over time.
The same is true for the player attributes.

Some descriptive statistics for team attributes can be seen in table~\ref{tab:desc-stat}.

\begin{table}[ht]
\centering
\begin{tabular}{rllllll}
  \hline
                 & Min     & 1st Qu. & Median  & Mean    & 3rd Qu. & Max \\
  \hline
buildUpPlaySpeed & 20.00   & 45.00   & 52.00   & 52.46   & 62.00   & 80.00   \\
  buildUpPlayPassing & 20.00   & 40.00   & 50.00   & 48.49   & 55.00   & 80.00   \\
  chanceCreationPassing & 21.00   & 46.00   & 52.00   & 52.17   & 59.00   & 80.00   \\
  chanceCreationCrossing & 20.00   & 47.00   & 53.00   & 53.73   & 62.00   & 80.00   \\
  chanceCreationShooting & 22.00   & 48.00   & 53.00   & 53.97   & 61.00   & 80.00   \\
  defencePressure & 23.00   & 39.00   & 45.00   & 46.02   & 51.00   & 72.00   \\
  defenceAggression & 24.00   & 44.00   & 48.00   & 49.25   & 55.00   & 72.00   \\
  defenceTeamWidth & 29.00   & 47.00   & 52.00   & 52.19   & 58.00   & 73.00   \\
   \hline
\end{tabular}
\caption{5-number summaries for team attributes}
\label{tab:desc-stat}
\end{table}

\subsection{Data Exploration}
With our objective in mind, the following two tables were of interest to us:
\begin{itemize}
  \setlength\itemsep{0em}
  \item Match
  \item Team\_Attributes
\end{itemize}
Although Player\_Attributes might give useful information about the strengths of the team, we haven't delved much into it as there are numerous attributes of the players and for each match, we would have to come up with a normalized attribute for the whole team.
This would have complicated our model and we aimed at keeping the model as simple as possible to avoid overfitting.

From the structure of the data, it is apparent that the rest of the tables, except player attributes, are used for indexing purposes (eg. foreign keys from leagues to countries).
These data entries, being nominal attributes, are just used to differentiate between two different entities and hence do not contribute towards finding out interesting patterns in the data.

\subsection{K-means Clustering}
K-Means clustering on team attributes provided some interesting insights.
First, we needed to pick a value for $k$.
To do this, we followed~\cite{cluster1}.
We performed k-means clustering for different values of $k$ from 2 to 12, and plotted the SSE for each $k$.
Our dataset had $n = ~25000$, so this process was relatively inexpensive in R.
The decrease in SSE from 2 to 3 was large but didn't change as much past that.
This told us that $k=3$ was an optimum number of clusters.
The plot is in figure~\ref{fig:sse}.

\begin{figure}[ht!]
  \centering
  \includegraphics[scale=0.5]{wss}
  \caption{Decrease in SSE as k increases.}
  \label{fig:sse}
\end{figure}

Once we had selected $k$, we performed k-means clustering on the team attributes for each year in 2010 to 2015.
To visualize the clustered team attributes, we performed Principal Component Analysis (PCA) to reduce the dimensionality from 8 to 2.
The PCA-reduced clusters are in figure~\ref{fig:clusters}.
We can see more variability between teams in 2010 than in subsequent years.
In other words, given two teams, it would be easier to categorize them in 2010 -- which presumably means that it would be easier to determine the outcome between two teams in different clusters.
For years 2011, the clusters are denser and closer together for the most part, indicating that teams were more closely matched up in 2011.
The remaining years see the teams moving further apart again, but not as much as 2010.

\textbf{Please note that the clustering took place on the original data.
PCA was used for visualization purposes only.}
We also performed clustering on all team attributes across the six years.
The centroids gleaned are in table~\ref{tab:centroids}.

\begin{table}[ht!]
\centering
\begin{tabular}{rrrr}
  \hline
 & C1 & C2 & C3 \\
  \hline
buildUpPlaySpeed & 57.55 & 56.53 & 41.69 \\
  buildUpPlayPassing & 48.81 & 53.75 & 39.61 \\
  chanceCreationPassing & 60.03 & 52.65 & 45.01 \\
  chanceCreationCrossing & 56.65 & 55.97 & 47.71 \\
  chanceCreationShooting & 60.99 & 50.98 & 53.20 \\
  defencePressure & 56.63 & 41.66 & 44.57 \\
  defenceAggression & 56.11 & 47.43 & 46.69 \\
  defenceTeamWidth & 59.92 & 49.49 & 50.34 \\
   \hline
\end{tabular}
\caption{Cluster centers for team attributes from 2010 to 2015.}
\label{tab:centroids}
\end{table}

Fairly clear distinctions can be seen between the clusters.
$C1$ has the highest scores on every attribute except for \textit{buildUpPlayPassing}, indicating that the teams in this cluster are generally better than the teams in the other clusters.

Comparing clusters $C2$ and $C3$, we see that for the first 4 attributes, the teams in $C2$ tend to have higher scores than $C3$.
For the next 4, the two clusters are fairly similar, with $C3$ even scoring higher on certain attributes.
A deeper look into the domain-specific meaning of the attributes suggests that the teams in cluster $C2$ are better than the teams in $C3$ in matters relating to \textbf{offense}.
The two clusters are on par with each other in matters relating to \textbf{defense}.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.6]{clusters}
  \caption{PCA-reduced clustered team attributes for 6 years.}
  \label{fig:clusters}
\end{figure}

\subsection{Data Preprocessing}
\label{sec:preprocessing}
Looking at Table~\ref{tab:data-desc} again, notice that Match and Team\_Attributes have 115 and 25 attributes, respectively.
The Match table contained the following relevant dimensions:
\begin{itemize}
  \setlength\itemsep{0em}
  \item season
  \item stage
  \item date
  \item home\_team\_id
  \item away\_team\_id
  \item home\_team\_goal
  \item away\_team\_goal
  \item goal
  \item shoton
  \item shotoff
  \item cross
  \item corner
  \item possession
\end{itemize}
\noindent
The Team Attributes provided were the following:
\begin{itemize}
  \setlength \itemsep{0em}
  \item buildUpPlaySpeed
  \item buildUpPlayPassing
  \item chanceCreationPassing
  \item chanceCreationCrossing
  \item chanceCreationShooting
  \item defencePressure
  \item defenceAggression
  \item defenceTeamWidth
\end{itemize}

All the above listed attributes are continuous.
In addition to them, the database also contained a discretized value for each attribute listed above.
For the preprocessing methodology we describe below, it was necessary to choose the continuous versions of these attributes.
Also, there existed an attribute called \textit{buildUpPlayDribbling} that was not present in 969 (66\%) Team\_Attribute rows.
This is a large percentage, and in addition to that, discarding rows with this NULL value would have had a ripple effect, causing us to discard too many matches.

Since the data was provided as a relational database, significant pre-processing steps were undertaken before modelling began.

Here, instead of tranforming the data to a new space using techniques such as Principal Component Analysis (PCA) or Multimdimensional Scaling (MDS), we have kept the data in its original state and used domain specific knowledge to hand pick some interesting features.
Handpicking the features we have reduced the dimensionality complexity from 115 to a little more than 10.

\subsection{Difference Vectors}
During our ideation phase, we realized that when two teams are facing each other, we would need a method with which to compare the two teams.
The simplest method to do this was to calculate a `difference vector' for each match -- a vector of the differences between each involved team's attributes.

The next question that arose was how to identify \textit{which} team we were making a prediction about.
Our solution was to change the problem from \textbf{Predicting the winner} to \textbf{Predicting the result for the home team}.
Doing things this way fell in line nicely for our concept of `difference vectors'.
If $h$ is a vector of the home team's attributes and $a$ is a vector of the away team's attributes, then $d = h - a$, where $d$ is the difference vector, \textit{from the perspective of the home team}.

For example, see the home team $h$, the away team $a$, and their difference vector presented in table~\ref{tab:diff}.
The vector $d = h - a$ for each match is what is passed to our models for prediction.

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
                                & \textbf{h} & \textbf{a} & \textbf{d = h - a} \\ \hline
\textbf{buildUpPlaySpeed}       & 61         & 50         & 11             \\ \hline
\textbf{buildUpPlayPassing}     & 46         & 54         & -8             \\ \hline
\textbf{chanceCreationPassing}  & 66         & 52         & 14             \\ \hline
\textbf{chanceCreationCrossing} & 66         & 54         & 12             \\ \hline
\textbf{chanceCreationShooting} & 54         & 46         & 8              \\ \hline
\textbf{defencePressure}        & 47         & 36         & 11             \\ \hline
\textbf{defenceAggression}      & 58         & 43         & 15             \\ \hline
\textbf{defenceTeamWidth}       & 53         & 47         & 6              \\ \hline
\end{tabular}
\caption{Difference vector}
\label{tab:diff}
\end{table}

\subsubsection{Which attributes to use?}
As mentioned in Section~\ref{sec:data-desc}, each team had several vectors of attributes associated with it, since they had potentially differing attributes each year.
As can be seen in figure~\ref{fig:clusters}, the distributions of team attributes were not static across the 6 years for which team information is available.
As a result, for a particular team playing a particular match, we used the vector of attributes with the date \textit{closest to the match date}.
This typically meant we used attributes from the same sporting season.

\subsubsection{Defining the outcome variable}
Recall that, for each match, the database provided a home\_goal count and an away\_goal count.
Since we had turned our problem into a prediction for the home team, we defined an $outcome$ categorical variable for each difference vector.
The variable has 3 levels: 0 if the home team lost, 1 if the match was a draw, and 2 if the home team won.

We also defined a $win\_percentage$ variable that looked at past encounters between two given teams.
This variable will be discussed in further detail in Section~\ref{sec:models}.

\section{Prediction Algorithms}
\label{sec:models}
We started by predicting if the home would \textit{win} or \textit{not win}.
Hence, we changed the outcome of the match from 0 (lose), 1 (draw), and 2 (win) to just 0 (lose or draw) and 1 (win).
After processing the data in a way that will be suitable for our intended task, we used various classification and regression models to come up with the outcome given two different teams and their respective attributes.
The algorithms we used are presented in this section.

\subsection{Decision Tree}
\textbf{Attributes Used:}
\begin{itemize}
  \setlength\itemsep{0em}
  \item buildUpPlaySpeed
  \item buildUpPlayPassing
  \item chanceCreationPassing
  \item chanceCreationCrossing
  \item chanceCreationShooting
  \item defencePressure
  \item defenceAggression
  \item defenceTeamWidth
\end{itemize}
\textbf{Decision Tree:}
Generated by THIS.\\
\textbf{Accuracy:} 50\%

Based on what we mentioned in our proposal, we initially implemented a decision tree classifier.
For the decision tree, we only used the attributes of the Difference Vector.
We trained the decision tree on 80\% of the data and used the remaining 20\% for testing.

Unfortunately, the decision tree did not perform particularly well.
We achieved approximately 50\% accuracy, which is essentially the accuracy of a random guess for a binary variable.
To improve these results, we decided to try another classification method.

\subsection{Binomial Logistic Regression - Predicting Win or Not Win}
We went through several versions of the logistic regression, makign strategic changes to the features involved each time. The details of each iteration are presented below.

\subsubsection{Iteration 1:}
The Match table contained betting odds as published by 10 bookkeeping companies.
The odds were presented as the odds of the home team winning (H), the odds of a draw (D), and the odds of the away team winning (A).
We added one company's odds to our featureset (for a total of 3 additional variables).
We trained a stepwise logistic regression using these features to predict 0 (lose or draw) or 1 (win).

Performing 5-fold cross validation, each time using 80\% as the training set and 20\% as the testing set, we achieved ~65\% accuracy.
This was encouraging, since it represented a 15\% jump from the accuracy achieved with a decision tree.
However, the Odds variables represented other professionals' predictions of the match outcome.
Hence, we did not want to use these predictors in our predictor. Therefore, we decided to remove those from the model.

\subsubsection{Iteration 2:}
We re-ran the logistic regression model with the same difference vector (table~\ref{tab:diff}) as we used for the decision tree. The average accuracy achieved by the logistic regression dropped to 54\%. The increase in accuracy from that of a decision tree is not significant in this case.

The confusion matrix for one of the testing runs (~5000 data entries) is given in table~\ref{tab:logistic-fusion1}.
\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|r|r|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}}                                     & \multicolumn{2}{l|}{Predicted class} \\ \cline{3-4}
\multicolumn{2}{|l|}{}                                                      & 0                  & 1               \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Actual\\ Class\end{tabular}} & 0 & 2694               & 9               \\ \cline{2-4}
                                                                        & 1 & 2410               & 13              \\ \hline
\end{tabular}
\caption{Logistic Regression Confusion Matrix\\Accuracy = 54\%}
\label{tab:logistic-fusion1}
\end{table}

The estimate table for the logistic model is presented in table~\ref{tab:logistic-fusion2}.

\begin{table}[ht!]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & z value & Pr($>$$|$z$|$) \\
  \hline
(Intercept) & -0.1835 & 0.0142 & -12.95 & 0.0000 \\
  buildUpPlaySpeed & 0.0017 & 0.0011 & 1.57 & 0.1163 \\
  buildUpPlayPassing & -0.0120 & 0.0011 & -11.15 & 0.0000 \\
  chanceCreationPassing & 0.0035 & 0.0011 & 3.21 & 0.0013 \\
  chanceCreationCrossing & 0.0061 & 0.0010 & 6.09 & 0.0000 \\
  chanceCreationShooting & 0.0050 & 0.0011 & 4.57 & 0.0000 \\
  defencePressure & 0.0131 & 0.0014 & 9.72 & 0.0000 \\
  defenceAggression & 0.0020 & 0.0012 & 1.64 & 0.1016 \\
  defenceTeamWidth & -0.0067 & 0.0013 & -4.98 & 0.0000 \\
   \hline
\end{tabular}
\caption{Estimates for the 2nd logistic regression}
\label{tab:logistic-estimate1}
\end{table}

\subsubsection{Iteration 3}
An accuracy of 54\% was a slight improvement from the Decision Tree, but not by much.
We could do better.

We decided that some new meaningful feature might help boost our accuracy.
To do this, we came up with a home team `Win Percentage' attribute for each match, and we added this to our feature vector for use in model-training.
We define `Win Percentage' as follows:
\begin{quotation}
  Given a match $M$, we find all previous encounters between the two teams involved\footnote{Given that the data is provided for past 6 years, we are fairly sure about a considerable number of encounters between any two teams. Hence, no matter which two teams are playing from given data, we will always come up with a non-zero win\_percentage for both teams. It is highly unlikely (for this dataset) to find a combination of a teams that haven't played each other in past.}.
  We calculate the home team's win percentage in these previous encounters.
  Keep in mind that the home team in match $M$ might not necessarily be the home team in previous matches, so we identified the `team of interest' by team\_id during these calculations.

  If two teams had draws in all of their previous encounters there would be a possibility of a zero win-percentage.
  To avoid the model thinking that this meant our `team of interest' had \textit{lost} all their games, we treated draws as wins for both teams.
\end{quotation}

Or, mathematically:
\begin{align*}
win\_percentage\_team1 &= \frac{\textrm{matches won by team1}}{\textrm{matches won by team1} + \textrm{matches won by team2}} \\
win\_percentage\_team2 &= \frac{\textrm{matches won by team2}}{\textrm{matches won by team1} + \textrm{matches won by team2}}
\end{align*}

We also calculated a `Possession Percentage' indicating the home team's possession percentage.

These calculations significantly increased pre-processing time, but the gain in model accuracy was worth it.
We performed 5-fold cross-validation, and the resulting average accuracy was ~74\%, displaying a \textbf{20\% increase} from the model without the win\_percentage feature.
The confusion matrix from one of the testing runs is presented in table~\ref{tab:logistic-fusion2}.

Note: We did a stepwise logistic regression, so some of the variables may not appear in the estimate table.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|r|r|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}} & \multicolumn{2}{l|}{Predicted Class} \\ \cline{3-4}
\multicolumn{2}{|l|}{}                  & 0                 & 1                \\ \hline
\multirow{2}{*}{Actual Class}    & 0    & 2451              & 252              \\ \cline{2-4}
                                 & 1    & 1149              & 1274             \\ \hline
\end{tabular}
\caption{Confusion Matrix for Logistic Regression using Win-Percentage and Possession Percentage\\Accuracy = 74\%}
\label{tab:logistic-fusion2}
\end{table}

The details of this model are presented in table~\ref{tab:logistic-estimate2}.
\begin{table}[h!]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & z value & Pr($>$$|$z$|$) \\
  \hline
(Intercept) & -4.3802 & 0.0681 & -64.34 & 0.0000 \\
  win\_percentage & 9.6293 & 0.1541 & 62.49 & 0.0000 \\
  buildUpPlaySpeed & -0.0029 & 0.0013 & -2.21 & 0.0269 \\
  buildUpPlayPassing & 0.0025 & 0.0014 & 1.83 & 0.0678 \\
  chanceCreationShooting & -0.0024 & 0.0014 & -1.74 & 0.0823 \\
  defenceAggression & -0.0042 & 0.0015 & -2.76 & 0.0057 \\
  defenceTeamWidth & -0.0041 & 0.0015 & -2.71 & 0.0067 \\
   \hline
\end{tabular}
\caption{Estimates for the Win/Not-Win Logistic Regression}
\label{tab:logistic-estimate2}
\end{table}

\subsection{Multinomial Logistic Regression - Predicting Win, Lose, or Draw}
So far, we have only been predicting 0 (lose or draw) or 1 (win).
The provider of the dataset mentioned that he achieved a 53\% accuracy while making this prediction.
We couldn't use a binomial logistic regression for this prediction, since that expects a binary outcome variable.
Instead, we used a multinomial logistic regression, implemented by the R package \textit{nnet}~\cite{nnet}.

Predictable, average accuracy from 5-fold cross-validation went down from 74\% (win or not-win) to ~63\% (win, lose, or draw).
We also only used the win\_percentage feature in this model, since the others contributed negligibly to the final equation.
While not satisfactory, this achieves our mentioned goal of surpassing the author's accuracy level of 53\%.
The detailed model is in table~\ref{tab:multinom-estimates}, and the confusion matrix is in table~\ref{tab:multinom-confusion}.

\begin{table}[h!]
\centering
\begin{tabular}{rrr}
  \hline
 & (Intercept) & win\_percentage \\
  \hline
1 & -1.72 & 5.16 \\
  2 & -4.72 & 12.79 \\
   \hline
\end{tabular}
\caption{Coefficients for the multinomial regression}
\label{tab:multinom-estimates}
\end{table}

\begin{table}[ht!]
  \centering
  \begin{tabular}{|c|c|r|r|r|}
    \hline \multicolumn{2}{|l|}{\multirow{2}{*}{}} & \multicolumn{3}{c|}{Predicted Class} \\
    \cline{3-5} \multicolumn{2}{|l|}{} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} \\
    \hline \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Actual\\ Class\end{tabular}} & 0 & 853 & 325 & 155 \\ \cline{2-5}
    & 1 & 278 & 375 & 247 \\ \cline{2-5} & 2 & 383 & 489 & 2021 \\
    \hline \end{tabular}
    \caption{Confusion Matrix for Multinomial Logistic Regression\\Accuracy = 63\%}
    \label{tab:multinom-confusion}
  \end{table}

\subsection{Ensemble Methods - Trying to do better than 63\%}
Implementing a multinomial regression reduced our accuracy considerably. Hence, we decided to train another stepwise binomial model that predicted 0 (win or draw) and 1 (lose). After 5-fold cross validation, we observed an accuracy of ~80\%. The features used by this model were 'win\_percentage' and 'possesion\_percentage'.

The confusion matrix for this model is given in Table~\ref{tab:justloseFusion}.

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|r|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}}                                                           & \multicolumn{2}{c|}{Predicted Class}               \\ \cline{3-4}
\multicolumn{2}{|l|}{}                                                                            & 0                         & \multicolumn{1}{c|}{1} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Actual\\ Class\end{tabular}}} & 0 & \multicolumn{1}{r|}{3544} & 68                     \\ \cline{2-4}
\multicolumn{1}{|c|}{}                                                                        & 1 & \multicolumn{1}{r|}{1018} & 496                    \\ \hline
\end{tabular}
\caption{Confusion Matrix for Predicting Lose or Not Lose\\Accuracy = 80\%}
\label{tab:justloseFusion}
\end{table}

The details of the model are in Table~\ref{tab:justloseCoeff}.

\begin{table}[h!]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & z value & Pr($>$$|$z$|$) \\
  \hline
(Intercept) & 2.1086 & 0.0516 & 40.83 & 0.0000 \\
  win\_percentage & -8.0385 & 0.1364 & -58.92 & 0.0000 \\
  pos\_percentage & 0.0831 & 0.0252 & 3.30 & 0.0010 \\
   \hline
\end{tabular}
\caption{Estimate Table for the Lose-Not Lose Logistic Regression}
\label{tab:justloseCoeff}
\end{table}

We treated these classifiers as two week classifiers, since they are both binary classifiers and do not predict the `Draw' outcome.
We implemented a meta classifier that took into account the predictions from the Win/Not-Win and Lose/Not-Lose classifiers to return a Win/Lose/Draw prediction. Unfortunately, the accuracy came out to ~53\%.

The confusion Matrix is given in Table~\ref{tab:012Fusion}.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|r|r|r|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}}                                     & \multicolumn{3}{c|}{Predicted Class}                                     \\ \cline{3-5}
\multicolumn{2}{|l|}{}                                                      & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Actual\\ Class\end{tabular}} & 0 & 496                    & 920                    & 98                     \\ \cline{2-5}
                                                                        & 1 & 54                     & 981                    & 154                    \\ \cline{2-5}
                                                                        & 2 & 14                     & 1135                   & 1247                   \\ \hline
\end{tabular}
\caption{Confusion Matrix from Ensemble Method}
\label{tab:012Fusion}
\end{table}

\section{Real-World Insights}
From our models, we can predict the following things:
\begin{itemize}
  \item Win or not: We can predict with 74\% accuracy whether a team will win a soccer match or not.
  \item Lose or not: We can predict with 80\% accuracy whether a team will lose a soccer match or not.
  \item Match outcome: We can predict with 63\% accuracy a team's outcome for a soccer match.
\end{itemize}

In Europe, where betting and bookkeeping are legal, there are obvious actionable benefits from such predictions.
For fans world over, an empirically-evaluated prediction for a match outcome is useful and interesting information.
The information can also be used for publicity purposes.
During big tournaments like the world cup, for example, commentators tend to speculate on match outcomes for dramatization purposes.

From our clustering efforts, we could also see that, based on the team attributes, there are roughly three classes of teams.
Coaches and players could benefit from this information, enabling them to understand teams' playing styles more deeply.
It could possibly also provide more assistance in match outcome predictions.

\section{Lessons Learned}
This project gave us some practical insights into data mining that were not possible to get from


\bibliography{report.bib}
\bibliographystyle{plain}
\end{document}
